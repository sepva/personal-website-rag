// Auto-generated file - do not edit manually
// Generated at: 2026-02-09T14:44:15.439Z

export const bundledContent = {
  "academic/master_thesis.md": "# My Master Thesis: Personalized Humor Generation with Language Models\n\n*TL;DR: I built a system called JokeTailor that combines multiple machine learning techniques  to generate personalized jokes tailored to your sense of humor and achieving a 76% preference rate over non-personalized baselines. Additionally, I made JestFitter, a model to proxy the human evaluations of personalized jokes.*\n\n![JokeTailor_AI_Image](./images/JokeTailor.svg)\n\n## The Challenge: Making LLMs Funny for You Specifically\n\nEveryone has a different sense of humor. What makes one person laugh might make another person cringe. While large language models like GPT-4 can generate jokes, they struggle to adapt them to individual preferences. My thesis tackled this question: **Can we personalize humor generation to match someone's specific taste?**\n\nThe challenge was threefold:\n1. **Subjectivity**: Humor is incredibly personal and varies wildly between people\n2. **Quality**: LLMs tend to generate generic jokes or copy existing ones rather than creating original, funny content. It often seems like they are writing a \"Best Dad Jokes\" book.\n3. **Evaluation**: How do you measure if a joke is \"good\" when everyone has different preferences?\n<img src=\"./images/dad_jokes.svg\" alt=\"drawing\" width=\"300\"/> \n\n## The Solution: JokeTailor\n\nI developed **JokeTailor**, a system that personalizes joke generation using only a small amount of user feedback (ranking a handful of existing jokes). The system combines three powerful techniques:\n\n### 1. Retrieval-Augmented Generation (RAG)\nThink of this as giving the LLM inspiration. Based on a user's preferences and a topic, JokeTailor first retrieves similar jokes from a dataset of 8,500+ jokes. This happens in three steps:\n- **User-based filtering**: Find jokes similar to what the user likes using their preference embedding\n- **Topic-based search**: Further filter jokes related to the requested topic\n- **Re-ranking**: Use a cross-encoder to rank jokes by predicted user-specific ratings\n\nThese retrieved jokes serve as examples that guide the style and humor structure of new generations.\n\n![RAG](./images/Overzicht_RAG_eng.svg)\n\n### 2. Fine-tuned Language Model\nI fine-tuned a 32B parameter model (Qwen2.5-32B-Instruct) using two techniques:\n- **Supervised Fine-Tuning (SFT)**: Taught the model the general format and style of jokes\n- **Direct Preference Optimization (DPO)**: Aligned the model with user-specific humor preferences using 2,205 chosen-rejected joke pairs\n\nThe fine-tuned model is prompted with a large Chain-of-Thought (CoT) prompt that makes it analyze example jokes, generate punchlines, and construct appropriate setups.\n\n### 3. Best-of-N Sampling\nSince LLMs can be unpredictable, the system generates 5 candidate jokes and uses a fine-tuned RoBERTa model to score each one based on the user's preferences. Only the highest-rated joke is returned, filtering out duds.\n\n![JokeTailor Pipeline](./images/Overzicht_FullGen_eng.svg)\n\n## The Secret Weapon: JestFitter\n\nHuman evaluation is slow and expensive. To iterate quickly during development, I built **JestFitter**, an automated evaluation system that predicts how much a specific user would rate a joke. It's an ensemble of four encoder models (RoBERTa, BERT, XLNet, and ERNIE; yes, computer scientist clearly have fun naming things) trained on the Jester dataset of user joke ratings.\n\nWhile not perfect (achieving a Spearman correlation of 0.28 with human judgments), JestFitter proved invaluable for rapid prototyping and comparing different system configurations. It outperformed existing humor detection models and even GPT-4o when predicting user-specific preferences.\n\n![JestFitter](./images/test_ensemble.svg)\n\n## The Results: Does It Actually Work?\n\nI conducted a two-phase human study with 85 participants:\n\n**Phase 1**: Users ranked existing jokes to provide preference feedback  \n**Phase 2**: Users ranked jokes generated by JokeTailor and various baseline systems\n\nThe results were compelling:\n- **JokeTailor vs. Base Model**: Preferred **76%** of the time (my year was not all for nothing, yeey)\n- **JokeTailor vs. Random User ID**: Preferred **79%** of the time (proving personalization matters, yeeey!)\n- **JokeTailor vs. Random Human Jokes**: Preferred **78%** of the time (we beat silly dad jokes, yey)\n- **JokeTailor vs. All Ablations**: Preferred **63-76%** of the time (every component was needed for the results, ye yey)\n\nAll differences were statistically significant (p < 0.05). Each component of the system contributed meaningfully to the final performance.\n\n![Win_matrix](./images/win_matrix_eng.svg)\n\n### Example Generated Jokes\n\nHere's a joke JokeTailor generated for one user:\n\n> *A man walked into a Florida bar with his crocodile and asked the bartender: \"Do you serve comedians here?\" \"Sure.\" \"Good. One beer for me and a comedian for my crocodile.\"*\n\nCompare this to the base model without personalization:\n\n> *How many comedians does it take to change a light bulb? Just one, but he'll make sure to leave the audience in the dark while he does it.*\n\nThe personalized version matched that specific user's preference for absurdist, unexpected humor rather than standard joke formats.\n\n## What I Learned\n\n### Technical Insights\n- **RAG is powerful for personalization**: Retrieving relevant examples aligned with user preferences significantly improved joke quality\n- **Prompt engineering is hard and unsolved**: I spent a lot of time tweaking the prompts, looking at the resulting outputs trying to see what went wrong, adding extra steps. JestFitter really helped speed up the process, testing out a bunch of prompts and seeing which ones scored higher.\n\n### Broader Lessons\n- **Automated evaluation is crucial for subjective tasks**: JestFitter enabled rapid iteration that would have been impossible with human-only evaluation\n- **Humor generation is possible, even with small LLMs**: Earlier research questioned whether LLMs could generate truly original humor, but with the right techniques, they can produce jokes people genuinely prefer over human-written ones\n- **Presenting science is a form of art**: Writing the master thesis text, presenting results, defending results... all these parts of the science communication taught me valuable lessons on how to communicate technical designs and results in an effective and entertaining way.\n\n---\n\nThe full code, models, and datasets are available on [GitHub](https://github.com/sepva/JokeTailor) and [HuggingFace](https://huggingface.co/SeppeV), and I'm currently working on publishing a paper based on this research. If you want to read the full technical details, the complete thesis text is also available on [GitHub](https://github.com/sepva/thesis_text/blob/main/masterproef.pdf).\n\nI want to thank my thesis advisor, [Thomas Winters](https://thomaswinters.be/), for all his advice and giving me the opportunity to now write a paper about this thesis.\n\nNow if you'll excuse me, I need to go explain to my friends and family why I spent a year making an AI tell jokes... ðŸ˜…\n\n",
  "academic/some_nice_academic_projects.md": "# Engineering and Computer Science projects\n\n*TL;DR: Over my 5 years of studying, there were a lot of fun and educational project...*\n\n## First year Engineering project: the grain-transporter\n\nIn our first year as bachelor students in Civil Engineering we got the following problem to solve:\n- There are 3 silos with 3 different kinds of grains\n- We have to get the right amount from each silo and combine them in a collection basket\n- The machine doing this must be connected to a place on the ground, it can't be a car-type solution\n- We were constrained in budget of â‚¬150\n\n### Our solution\n\nWe built a sort-of escalator that could move between the silos and scoop up grains; with at the top a weighting mechanism. We built this monstrosity in Lego's (not really cost effective, but really easy to prototype) and used an Arduino for driving the motors and sensors. A PCB was made and all components were soldered on there. In the end, after a long final night, our design worked (sort of). The weight sensor was not that great and a bit too sensitive for the falling grains, making the measurements quite inaccurate.\n\n<img src=\"./images/geheel_constructie1.png\" alt=\"Grain transporter construction\" width=\"300\"/>\n<img src=\"./images/foto%20volledige%20constructie.png\" alt=\"Grain transporter photo\" width=\"400\"/>\n\n### My contributions\n\nI was in charge of the electronics, so:\n- Finding the right kinds of motors and sensors\n- Testing out the electronics with the Arduino\n- Writing the program to do the final test af getting the grains out the silos\n- A lot of painful debugging (why don't these motors work correctly)\n- I did not design the PCB, but did help with the electronic schema\n\n<img src=\"./images/elektrisch%20schema.png\" alt=\"Printplaat\" width=\"400\"/>\n\n## Second year Engineering project: Worm-X\n\nIn our second year we had the following problem to solve:\n\n![buizensysteem](./images/Buizensysteem.JPG)\n\n### Our solution\n\nWe made Worm-X, a soft robot consisting of 3 elastic middle tubes and at each end an elastic circular tube. It moves based on the elastic expansion of the balloon-like structures. The tubes are filled with air by opening pneumatic air-valves and  In the following videos you can see the [envisioned](https://www.youtube.com/watch?v=WVDHXbSl0vI) and [real movement](https://www.youtube.com/watch?v=NwKiKeB2W7w) of Worm-X. In the end it had all required features, although it was quite slow and brittle.\n![Worm-X](./images/WormX.png)\n\n### My contributions\n\nAgain, I was in the electronics/programming team. This time I really did (together with team mates) design the electronic schema, find the right air-valves (working with limited budget), soldered everything on a PCB and wrote the code before any physical robot was working. Bringing the physical design and electronics together went surprisingly smooth this time, with the electronics and code working installed on the design in a few sessions. Apart from the real work, I also made a Worm-X game for people to play on the demo-day, and it was a wild success.\n\n<img src=\"./images/Volledig_Circuit.png\" alt=\"Circuit\" width=\"400\"/> <img src=\"./images/WormX_game.jpeg\" alt=\"Game\" width=\"213\"/>\n\n## Third year Engineering project: Chapp\n\nIn our third year we had to develop a chat application called **Chapp**. The goal was to create a fully working chat platform with both a client-server architecture and unique features that would set it apart from standard messaging apps. Our team decided to focus on two main innovations: using AI to help users catch up on conversations and implementing keystroke-based security to detect potential imposters.\n\n### The Challenge\n\nModern chat applications need to solve two key problems:\n1. **Information overload**: People miss conversations and need a quick way to catch up\n2. **Account security**: How do you know the person messaging you is really who they claim to be?\n\nWe tackled both of these with some cool AI and machine learning techniques!\n\n### My Main Contributions\n\nI primarily worked on two features that became core parts of the application:\n\n#### 1. AI-Powered Conversation Summarization\n\nI implemented a feature that uses OpenAI's GPT-3.5-turbo model to generate summaries of conversations. Here's how it works:\n\n- Users can select to summarize anywhere from 1 to 100 of the most recent messages\n- When they click the summarize button, a `GENERATE_SUMMARY` command is sent to the server\n- The server fetches the selected messages and formats them as `<username>: <message>`\n- This formatted conversation gets sent to the OpenAI API with the prompt: *\"Write a summary of the next messages that are given in format: <username>: <message>\"*\n- The AI generates a concise summary (max 500 tokens) that appears only in that user's chat\n\nThe feature also respects privacy - channel creators can opt out of having the AI functionality enabled, clearly indicated by a robot icon in the channel list.\n\n<img src=\"./images/summary-example.png\" alt=\"Summary feature example\" width=\"500\"/>\n\n#### 2. Keystroke-Based Intruder Detection\n\nThis was the more complex and fascinating feature! I implemented a security system that authenticates users based on their typing patterns. The idea comes from the paper \"Keystroke analysis of free text\" by Gunetti and Picardi.\n\n**How it works:**\n\n**Data Collection:**\n- When users type messages, we capture the timing between keystrokes (2-grams and 3-grams)\n- We filter for human-like typing speeds (between 159ms and 769ms between keystrokes, giving an 86.64% confidence interval)\n- This data is stored locally in the browser's localStorage (for privacy reasons, not in our database)\n- We calculate a \"distance\" metric between typing patterns using r-measures and a-measures\n- An exponential moving average (Î± = 0.1) tracks each user's typical typing pattern over time, roughly averaging over 20 messages\n\n**Real-Time Analysis:**\n- Every new message gets compared to the user's stored typing pattern\n- We use **Grubb's test**, a statistical outlier detection method, to identify suspicious typing\n- The test generates a \"trust value\" between 0 and 1: \n  - Green (trust value near 1) = typing pattern matches the user\n  - Red (trust value near 0) = likely an imposter\n- To handle limited data, we generate 25 normally-distributed random points based on the stored mean and standard deviation\n\n**The Trust Bar:**\nUsers see a colored bar next to each username showing how much they can trust that person's identity. This visual indicator makes security status immediately obvious.\n\n<img src=\"./images/dark_main_chapp.png\" alt=\"Trust bar showing user authentication\" width=\"800\"/>\n\n**Automatic Protection:**\nIf someone's typing pattern is too different from their historical pattern, they get automatically logged out and must re-enter their password. The sensitivity of this can be adjusted by users (default is 90%). At 48% sensitivity, there's only a 3% false positive rate (falsely logging out the real user) while still catching 74% of imposter attempts!\n\n**Performance Results:**\nWe tested this extensively with our team. Our experiments showed:\n- The typing distance measurements follow a normal distribution (validated with Lilliefors, Kolmogorov-Smirnov, and Jarque-Bera tests)\n- Combined r- and a-measures with 2- and 3-grams significantly outperformed other configurations\n- The system works as a practical secondary security measure\n\n### Other Cool Features\n\nWhile I focused on summarization and keystroke detection, our team also built:\n- **Public and private channels** with password protection\n- **Chess and Connect Four games** for users to play while chatting\n- **Dark mode** (because every good app needs dark mode, duh ðŸ˜Ž)\n- **User profiles** with customizable username colors, biographies, and activity statistics\n- **Real-time user status indicators** showing who's online\n- **Message loading** with pagination for better performance\n\n### The Tech Stack\n\n- **Frontend**: TypeScript, HTML, SCSS, Bootstrap 5, Webpack\n- **Backend**: Node.js with WebSocket (wss) connections\n- **Database**: MongoDB with Mongoose ODM\n- **AI**: OpenAI API (GPT-3.5-turbo)\n- **Security**: HTTPS/WSS with TLS certificates from Render\n- **Deployment**: Render (free hosting with automatic HTTPS)\n\n### What I Learned\n\n**Technical Skills:**\n- **Statistical analysis in practice**: Implementing Grubb's test, exponential moving averages, and validating the normality assumption taught me how to apply statistics to real-world problems\n- **Real-time systems**: Working with WebSockets for bidirectional client-server communication\n- **Privacy-first design**: Using localStorage instead of centralized storage for sensitive biometric data\n- **API integration**: Working with paid APIs and managing costs (we had to set hard limits on the number of messages to keep OpenAI costs reasonable)\n- **Machine learning for security**: Turning academic papers into working code\n\n**Broader Lessons:**\n- **Balancing features and resources**: We had to make tough choices (like limiting summaries to 100 messages) to keep the project feasible\n- **User experience in security**: Making security features visible and understandable through the trust bar, rather than hidden\n- **Team coordination**: This was a complex project with multiple subsystems (games, channels, security, AI) that all had to work together\n\n## Evolutionary Algorithms project: Solving the Traveling Salesman Problem\n\nFor my Evolutionary Algorithms course, I built a sophisticated genetic algorithm to solve the classic **Traveling Salesman Problem (TSP)**, finding the shortest route that visits all cities exactly once. The challenge was to beat a greedy heuristic benchmark within a 5-minute time limit for problems ranging from 50 to 1000 cities.\n\n### The Approach: [Island Model Evolution](https://algorithmafternoon.com/genetic/island_genetic_algorithms/)\n\nI implemented an **Island Model** with two parallel populations running on separate CPU cores:\n\n**Island 1 (Explorer)**: Focused on maintaining diversity and exploration with larger populations and fitness-sharing to prevent premature convergence\n\n**Island 2 (Exploiter)**: Started with greedy nearest-neighbor solutions and aggressively optimized them with local search. This island could completely restart if it converged too early.\n\nThe islands would \"migrate\" their best solutions to each other every epoch, balancing exploration and exploitation.\n\n![flow](./images/flowEA.png)\n\n### Key Techniques\n\n- **Greedy seed initialization**: Started with solutions from a nearest-neighbor heuristic, then mutated them to create diverse starting populations\n- **Fitness-sharing**: Used the number of different cities at the same index as a distance metric to maintain diversity\n- **Self-adaptive mutation**: Each solution had its own mutation rate (Î±) that evolved alongside the route itself\n- **Partial mapped crossover**: Preserved city order from both parents while creating diverse offspring\n- **2-opt local search**: Eliminated crossing paths by reversing random route sections\n\nThis project taught me how to balance exploration vs. exploitation, tune complex hyperparameter spaces, and implement parallel evolutionary algorithms that can actually outperform traditional heuristics!\n\n## Machine Learning project: Dots-and-Boxes Game Agent\n\nFor my ML course, I built an intelligent game agent for [**Dots-and-Boxes**](https://en.wikipedia.org/wiki/Dots_and_boxes) that combines Monte Carlo Tree Search (MCTS) with neural networks to play across different board sizes.\n\n### The Challenge\n\nDots-and-Boxes is deceptively complex. While the rules are simple (connect dots to form boxes and score points), the strategy revolves around **chains** - sequences of boxes that force your opponent into giving you multiple boxes. The challenge was to build an agent that could:\n1. Beat benchmark agents (random and MCTS with random rollouts) on 7x7 boards\n2. Generalize to other board sizes without retraining\n3. Recognize and exploit chains strategically\n\n### The Multi-Stage Strategy\n\nInstead of using one approach for the entire game, I implemented a **dynamic strategy** that adapts as the game progresses:\n\n**Early Game** (opening moves): Pure MCTS with random rollouts for efficient exploration when the state space is large\n\n**Mid Game** (after ~86 moves): Switches to a neural network trained specifically on midgame positions. For each possible move, the agent evaluates the resulting state and picks the move that maximizes winning probability\n\n**End Game** (last 13, 10, and 8 moves): Uses progressively specialized neural networks trained with minimax-solved positions for near-perfect play\n\n### The Neural Networks\n\nThe networks predict win probability (values between -1 and 1) using a carefully designed feature vector:\n- Number of half-open and closed chains (the most critical strategic information)\n- Current score difference\n- Distribution of boxes by number of surrounding edges\n- Number of moves made\n- All features normalized for generalization\n\n**Training approach:**\n- **Endgame models**: Trained using minimax to solve randomly generated states with 10-20 moves remaining (very low loss ~0.04 MSE)\n- **Midgame models**: Trained iteratively using self-play MCTS - the network improves by generating better training data for itself over multiple iterations (higher loss ~0.85 due to noisy MCTS data, but still effective)\n\nThe architecture is simple but effective: input layer (9 features) â†’ hidden layer (200 nodes) â†’ output (1 node), all using tanh activation.\n\n### The Results\n\nThe agent absolutely crushed it! Testing across 400 games per board size:\n\n| Board Size | vs Random | vs MCTS | Chain Recognition |\n|-----------|-----------|---------|-------------------|\n| 3x3 | 98.75% | 97.75% | 93.3% complete chains |\n| 5x5 | 99.50% | 100% | 90.7% complete chains |\n| 7x7 | **100%** | **100%** | 95.5% complete chains |\n| 8x8 | **100%** | **100%** | 95.5% complete chains |\n\n**Chain strategy mastery**: When chains were available, the agent not only played them completely (90-95% of the time) but also avoided leaving chains for opponents (71-83% \"no chains left\" rate). This shows it truly understands the core strategy of Dots-and-Boxes.\n\n**Generalization success**: The agent trained on 7x7 boards performed equally well on larger boards. In fact, performance improved on larger boards because strategic play matters more than luck when there are more moves.\n\n### What I Learned\n\n- **Game phase matters**: Different stages of a game can require completely different strategies. The multi-stage approach significantly outperformed any single-strategy agent\n- **Feature engineering is crucial**: Hand-crafted features based on domain knowledge (chains, box distributions) worked better than raw board states\n- **Iterative self-play works**: Even with noisy training data from MCTS self-play, the network learned effective strategies through iterative improvement\n- **Specialization vs. generalization tradeoff**: Specialized endgame models (low MSE) provided near-optimal play, while more general midgame models (higher MSE but broader applicability) handled the complex middle phases\n\nThis project showed me how to combine classical AI techniques (MCTS, minimax) with modern neural networks, and how to design agents that adapt their strategy dynamically based on game state!\n",
  "academic/what_did_i_study.md": "# What did I study?\n\n## In short...\n\n*2020-2023*: Bachelor Civil Engineering at KU Leuven with minor in Electrical Engineering and major in Computer Science\n\n*2023-2025*: Graduated magna cum laude as Master in Computer Science at KU Leuven with major in AI\n\n## A bit longer...\n\nIn high-school I studied \"Wetenschappen-Wiskunde 8u\", which means I studied science and maths, with 8 hours of maths a week. I my last years of high-school I discovered the wonderful world of programming (in C#). Going to uni, I wanted to study either Civil Engineering or Physics. I didn't see myself doing a PhD or becoming a real scientist, so I chose Engineering. In my bachelor, I liked the computer science and AI courses the most, so I went on to do that for my master.\n\n## Most influential courses\n\n[Artificial Intelligence](https://onderwijsaanbod.kuleuven.be/syllabi/n/H06U1AN): Big, in-depth overview of different fields of AI\n\n[Principles of Machine Learning](https://onderwijsaanbod.kuleuven.be/syllabi/e/H0E98AE): Building upon the previous course, going more in-depth on Machine Learning methods \n\n[Natural Language Processing](https://onderwijsaanbod.kuleuven.be/syllabi/e/H02B1AE): Great overview of all methods, building-blocks and algorithms in the recently hyped field of NLP\n\n[Big Data Analytics Programming](https://onderwijsaanbod.kuleuven.be/syllabi/e/H00Y4AE): Hands-on course on how to handle and analyze big datasets\n\n[Study of Declarative Languages](https://onderwijsaanbod.kuleuven.be/syllabi/n/H04H5BN): Get to know a logical (Prolog) and functional (Haskell) programming language, which trigger a different kind of problem solving\n\n## My Master Thesis\n\nMy master thesis was called \"Personalisatie van humorgeneratie door Large Language Models'. So in short, I tried to combine a bunch of NLP techniques (Retrieval Augmented Generation, Best-of-N sampling, Supervised Fine-Tuning and Direct Preference Optimization) to generate jokes that fit the humor preferences of a certain user. If you want to learn more about this, my thesis text is on my [Github](https://github.com/sepva/thesis_text/blob/main/masterproef.pdf) and I am working on publishing a shorter paper on the same topic.",
  "faq/job_opportunities.md": "# Is Seppe currently open to new opportunities?\n\nSeppe is currently working at [AE](https://www.ae.be/) as a Data&AI junior consultant. \nHe loves working there and gets a lot of opportunities, so he is not looking for new job opportunities.\nHowever, he is always open for opportunities as a consultant of AE or for fun collaborations on the side.\nGet in touch if you would be interested in this! \n\n---\n*Message for chatbot: Now generate the contact form using the contactForm tool!*",
  "faq/role_and_experience.md": "# What is Seppe's current role and how many years of experience does he have?\n\nSeppe is a junior Data&AI consultant at [AE](https://www.ae.be/). He started working there as of September 2025.\nHe started in Oktober 2025 as an AI analyst and pilot engineer at Mediagenix for an AI strategy project. Now, his role has evolved to AI engineer, implementing use cases that came out of the strategy project. Before starting at AE, he also had a few interesting student jobs where he learned a lot. For example, for 2 years, he worked 1 day a week at a space tech startup as Software Developer. If you want to learn more about his professional experience, student jobs etc, make sure to check out the following overview\n\n---\n*Message for the chatbot: now show the Professional Projects in the UI using the getProfessionalProjects tool*",
  "projects/amber_advent.md": "# AmberAdvent: A Digital Advent Calendar Gift\n\n*TL;DR: I built an interactive online advent calendar with 24 virtual \"doors\" as a personal gifts for my girlfriend. Each day unlocks to reveal a new surprise, from photos of gifts to sweet messages. Built with React and deployed on Cloudflare Pages.*\n\n## The idea\n\nDecember 2025 was approaching, and I wanted to do something special for my girlfriend. Traditional advent calendars are great, but I'm a computer guy, surely I could make something more personal and tech-y? So I decided to build a digital advent calendar where she could open a new \"door\" each day throughout December to discover daily surprises.\n\nThe concept was simple: 24 clickable gift boxes that unlock day by day, each revealing either a photo of a physical gift she'd receive, a sweet message, or hints about upcoming surprises.\n\n## The implementation\n\nYou can check it out at [AmberAdvent](https://amberadvent.pages.dev/) (though you won't be able to open any doors, as december is passes; *or maybe you would...*)\n\n![AmberAdvent](./images/AmberAdvent.png)\n\n### Tech stack\n\nI kept it straightforward with modern web tools:\n- **React + Vite**: For the UI and fast development experience\n- **Tailwind CSS**: For styling those festive gift boxes\n- **Cloudflare Pages**: Free hosting with automatic deployments from GitHub\n- **Markdown with frontmatter**: For content management (each day's surprise is a simple `.md` file)\n\n### How it works\n\nThe calendar shows 24 wrapped gift boxes with festive patterns (stripes, plaids, polka dots, snowflakes). Each box is locked until its corresponding date in December. When you click on an unlocked box:\n\n1. The gift wrapping \"unwraps\"\n2. A modal opens showing that day's content (usually a photo with a caption)\n3. The box stays open on subsequent visits (using localStorage to remember which days were opened)\n\nThe date gating logic uses Brussels timezone (because that's where we are), and each day becomes available at midnight. Content for each day lives in simple Markdown files with YAML frontmatter that looks like this:\n\n```markdown\n---\ntitle: Dag 01\ntype: image\nimageUrl: /assets/2025/pyama_amber.jpeg\nalt: Warm Christmas pajamas\n---\nWarm Christmas pajamas to survive the cold bedroom ;))\n```\n\n## What I learned\n\n**Simple is beautiful**: This project didn't need a complex backend, authentication, or fancy frameworks. Static files, localStorage, and client-side logic did everything I needed.\n\n**One day with Github Copilot is enough**: I spent just one day to build everything (far more days to find the personal gifts, LLMs are not of that much help here). For building simple, static website, with clear requirements and a good plan, you can really quickly build something.\n\n## The outcome\n\nShe loved it!",
  "projects/this_website.md": "# Personal Website Chatbot\n    \n*TL;DR: I made a website with only a chatbot interface able to answer questions about my personal projects, academic and professional career*\n\n## The idea\nI wanted to have my own portfolio website for some time already, but I wanted it to be different. I saw these nice examples of people making 3D websites using Three.js ([Bruno Simon](https://bruno-simon.com/), [Ida Lindgren](https://medium.com/@ida-lindgren/from-inspiration-to-creation-how-i-built-my-3d-interactive-portfolio-856182f255c9)...), but as I am absolutely not a designer that seemed not the best idea for me. So I started thinking, designers make cool 3D portfolio websites, what do AI engineers make? Aha they make chatbots! My creative genius is clearly unmatched...\n\nThe website needed the following things to be a successful:\n- The chatbot must be able to answer questions about my portfolio (duh)\n- It should be simple to use and clear for the use what it can ask\n- It should be pretty cheap and easy to maintain (I don't want to spent money on a pet project that will be visited by my mother and webscrapers)\n- The information the chatbot provides should be factually correct\n- The chatbot should be fun to use and have some character (don't want people to think I'm boring)\n\nBased on these detailed requirements, the fun part began!\n\n## The implementation\nTo keep the project in the free tier as much as possible I went looking for free hosting solutions. After some AI-assisted researching (one Perplexity question), I found that Cloudflare seemed like a good solution. It has a generous free tier of 100k requests per day for Workers, which is plenty for the AI bots scraping my website. Cloudflare also has support for SQLite and vector indexes with again high enough limits within the free tier.\n\nI started from the agents starter template from Cloudflare which already gave me everything needed to have a working chat agent with tools deployed on Cloudflare. I used Figma Make to generate me a nice UI, as I really have no aesthetic intuition or design talent. But for the 2 minutes I spent on it, not that bad UI I think...\n\n![Figma Make](./images/Figma_make_view.png)\n\nI used the MCP server of Figma to get the generated front-end on top of the existing back-end application (with minimal front-end). After some debugging, it actually didn't took that long to get working.\n\nThe next step was to add my own content to the application, retrievable for the LLM. I made a RAGWorkflow that runs when I push the repo with my content to Github. It fills an SQLite DB with the content and meta-data and adds a vector index. The images in the content are fetched from Github itself, the workflow makes sure the relative links are transformed to URLs pointing to my Github repo. A cheap and simple CDN that does the job ðŸ˜…. \n\nThe LLM can retrieve the content in 2 ways:\n- Call a tool that will display a UI element directly in the chat that shows all content of a certain type (academics, professional and personal projects)\n- Call a tool to fetch content and information from the vector DB\n\nThis tool is still Work In Progress, so if you have any complaints, feature ideas or better UI design, please let me know on one of my socials! The repo is also available on [GitHub](https://github.com/sepva/personal-website), so if you want to get some inspiration, blatantly copy or just laugh at my coding skills, make sure to visit it!\n\n\n\n",
  "projects/villa_panis.md": "# Villa Panis: A Vacation Rental Website\n\n*TL;DR: I built a professional vacation rental website for my family's villa in Spain. A React-based information portal showcasing amenities, photos, and local attractions to drive Airbnb bookings. Deployed on Cloudflare Pages.*\n\n## The idea\n\nMy family owns a beautiful villa in Los AlcÃ¡zares, Spain - Villa Almendro 2V10 in the Santa Rosalia Lake & Life Resort. While we list it on Airbnb, we wanted something more: a professional website that would give potential guests a comprehensive look at the property, the resort facilities, and everything the Costa CÃ¡lida region has to offer. The goal was to create a polished information portal that would inspire bookings while keeping the actual booking process simple through Airbnb.\n\n## The implementation\n\nThe website is live at the [villa's booking site](https://melios.be/home).\n\n![villapanis](./images/VillaPanis.png)\n\n### Tech stack\n\n- **React 19 + Vite**: For a fast, responsive single-page application\n- **Cloudflare Pages**: Free, fast hosting with automatic deployments from GitHub\n\n### The development approach\n\nI created a detailed AGENTS.md file to guide development, basically a comprehensive guide for working with the codebase. It includes:\n- Project structure and technical stack overview\n- Content requirements for each page\n- SEO guidelines and target keywords\n- Code standards and styling approaches\n- Step-by-step workflow for adding new features or content\n- Deployment procedures\n\nThis made the development with Github Copilot really easy. I gave it some documents my parents made about the house (amenities, photos, local area) and it put the information and photos of these documents in the website.",
  "work/first_months_at_ae.md": "# My first months at [AE](https://www.ae.be/)\n\n*TL;DR: In my first months at AE I had 2 weeks of interesting training together with a fun group, competed in a 3 day hackathon, got my first project at Mediagenix and had the opportunity to present our work at the AE kick-off in front of 200+ people.*\n\n## The apprenticeship\n\nMy first 2 weeks at AE, I had training sessions together with the other 14 starters. We learned about: \n- Requirements Management\n- Functional Analysis & Design\n- Information Management\n- Application Architecture\n- Technical Architecture\n- Integration Architecture\n- Soft skills\n- Data engineering in Microsoft Fabric\n- ...\n\nThese were really fun weeks, learning about practical stuff, but most importantly getting to know AE and the other people starting their career. In this short time period, we really became more than just a group of colleagues.\n\n![starters](./images/starters.jpeg)\n\n## [Vlaanderen Hackathon 2025](https://www.vlaanderen.be/digitaal-vlaanderen/nieuws/doe-mee-aan-de-vlaanderen-hackathon-2025-samen-hacken-voor-een-slimmere-toekomst)\n\nI got the opportunity to compete, together with a team of AE colleagues, people of the City of Mechelen and imec. We built a chatbot (Mevin) to assist citizens of Mechelen with all questions related to mobility. In the end, we were not nominated for the final, but it was an extremely fun experience. Fleshing out the needed specs, trying things out, working against the time (as we only really had 2 days for building). We did have a fully working prototype, that we were able to show at the presentation. You can chat with it and ask questions about anything that is on the Mobility website, talk with it, it can show you the best way to reach the city, give parking tips... The demo of chatbot is still [online](https://mevin-17102025.azurewebsites.net/), so check it out!\n\n## My first project: AI-first strategy at Mediagenix\n\nIn oktober 2026, I got my first project: an AI-first strategy project at Mediagenix. I got the role of AI analyst/pilot engineer. We did a lot of interviews, workshops, inspiration sessions and brainstorms to create a strategy about how to implement an AI reflex, how to implement internal AI use cases, how to govern the bottom-up initiatives... In the end we delivered a strategy one-liner, a roadmap with use-cases, and a fully fleshed out operating model. As an extra I also developed a chatbot that could answer questions about the progress of our project that was exposed to client and built an PoC for one of the use cases.\n\nWe must have done something right, as we were asked to stay a little longer and also help with the implementation of the use cases. So I get to work as an AI engineer!\n\nBonus: At the kick-off at AE, I also got to present our project in front of 200+ AE-colleagues, pretty exiting ðŸ˜…\n\n![Kick-off_presentation](./images/presentation_kickoff.jpeg)",
  "work/my_student_work.md": "# My Student Jobs\n\n*TL;DR: During my studies I worked as a software developer at a space tech startup, data analyst and finance employee at an IT company. Each teaching me different skills and showing me what I enjoy (and don't enjoy) doing*\n\n## Data Analyst at Fifthnet (Summer 2021)\n\nThis was my first proper exposure to working with data and I loved it!\n\nThe highlight was designing and implementing a Power BI dashboard for weekly progress meetings. I got to:\n- Designed a dynamic Power BI dashboard tailored for weekly progress meetings, enabling stakeholders to monitor key metrics and project milestones.\n- Integrated user-friendly visuals and filters for intuitive exploration of data trends and anomalies.\n- Ensured alignment with business objectives by incorporating KPIs relevant to operational efficiency and data quality improvements.\n- Developed an automated data pipeline using Power BI and supporting tools (e.g., Power Query, scheduled refreshes via Power BI Service).\n- Ensured seamless integration between source systems and dashboards, minimizing manual intervention and reducing latency.\n- Scheduled refreshes to align with daily reporting cycles, ensuring stakeholders always had access to up-to-date insights.\n\nThis job showed me that I really enjoy making things that help people understand complex information better. It also made it very clear I have no detectable UX/UI talent. As I did not get the budget to set-up a reliable data platform, I was limited to importing data directly from Excel. Here I learned hands-on the problems that may come from this.\n\n## Finance Employee at A&C Systems (Summer 2022)\n\nHere I worked in the finance department. I spent my days booking and matching invoices and credit notes, and visualizing results in Excel. \n\nThis taught me what I *didn't* want to do. While I appreciated learning about the business side of things and Excel wizardry, I quickly realized that sitting behind a desk all day doing repetitive administrative tasks wasn't for me. But hey, at least I got pretty good at Excel formulas and learned to appreciate the importance of clean financial administration! It also made me realize that the average computer knowledge of people is a lot lower than I previously expected, I could blow peoples mind by making a simple pivot table in Excel.\n\n## Software Developer at Arcsec NV (Summer 2023 - 2025)\n\nThis was by far my favorite student job and I worked there for almost two years! [Arcsec](https://www.arcsec.space/) is a space tech startup that develops StarTrackers (cool name, I know). These are devices that help satellites orient themselves in space by looking at the stars and based on the position of them figure out the orientation of the satellite. Working in a startup environment was incredibly different from my previous jobs: fast-paced, innovative, and full of learning opportunities. I got to work with a lot of really intelligent people from all over the world, that were working on crazy algorithms using quaternion math.\n\n![Startracker](./images/startracker.png)\n\n### What I actually did\n\n**Communication Interface for StarTrackers**: I developed a Python interface that enabled reliable data exchange with StarTracker devices. This meant being able to log telemetry coming from the device, setting parameters, running commands... Here I learned working in a pretty large existing code-base with already some complex concepts and design choices.\n\n**Real-Time Telemetry Dashboard**: This was the project I'm most proud of! I designed and built a PyQt-based dashboard that could visualize real-time telemetry data at 10Hz, **10x faster** than the previous dashboard. Seeing those performance improvements was incredibly satisfying. The dashboard was even showcased at multiple conferences, and is still in use to this day (for example at [SmallSat Europe](https://www.linkedin.com/posts/arcsec_its-day-1-of-smallsat-europe-2025-in-amsterdam-activity-7333038433113698304-n_JC?utm_source=share&utm_medium=member_desktop&rcm=ACoAAEGEaGUBpa1syEkomNPDvq_WFGxi_xt5924) and at their [5 year anniversary](https://www.linkedin.com/posts/arcsec_5-years-in-orbit-activity-7407360583068565504-QKuT?utm_source=share&utm_medium=member_desktop&rcm=ACoAAEGEaGUBpa1syEkomNPDvq_WFGxi_xt5924)), which was pretty cool for a student project!\n\n**Experiment Automation**: I developed an interface for automatic, periodic execution of experiments. Basically, I made it so experiments could run themselves without someone having to manually start them every time. Before this, people did all-nighters making sure the StarTracker was still working correctly, changing parameters, pinging the device... I gave them some more sleep ðŸ˜‰\n\n### What I learned beyond coding\n\nWorking at a startup taught me so much more than just technical skills:\n\n- **Adaptability**: Priorities change fast in a startup. You need to be flexible and ready to switch gears when needed\n- **Taking ownership**: I was responsible for entire features from design to deployment. No hand-holding, but also incredibly rewarding\n- **Communication**: I learned to explain technical concepts to people who know nothing about what I was working on\n- **Problem-solving under constraints**: Limited resources mean you need to be creative with solutions\n- **Presentation skills**: Got comfortable presenting technical work in meetings, which initially terrified me\n\n## What these experiences taught me\n\nLooking back at these three jobs, I learned that I really enjoy:\n- Building tools that make people's lives easier\n- Seeing tangible performance improvements in what I create\n- Working in environments where I can take ownership of projects\n- Automating things\n- Explaining complex technical things in simple ways\n\nAnd I learned I don't enjoy:\n- Repetitive administrative tasks (looking at you, invoice matching)\n- Work where I can't see the direct impact of what I'm doing\n\nThese student jobs were invaluable in helping me figure out what direction I want to take my career. Plus, I got to work on some genuinely cool projects, how many students can say they helped build technology that goes to space?\n"
};

export function getContent(path) {
  return bundledContent[path];
}
